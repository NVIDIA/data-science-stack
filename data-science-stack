#!/bin/bash

# Copyright (c) 2019, NVIDIA CORPORATION. All rights reserved.

# Global Paramaters
STACK_VERSION=2.8.0-dev
NOTEBOOKS_VERSION=0.17

MIN_DRIVER=460.39
MIN_CUDA=11.0.228
MIN_DOCKER=20.10.3
MIN_CONDA=4.8.3

SCRIPT_NAME=$(basename $0)
RUNFROM=$(dirname $(readlink -f $0))
DEFAULT_ENVIRONMENT="data-science-stack"
LOGFILE=data-science-stack.log

CONDA_ROOT=${HOME}/conda
DEFAULT_NOTEBOOKS_DIR=${HOME}/data-science-stack-${STACK_VERSION}
NOTEBOOKS_DIR=${NOTEBOOKS_DIR:-$DEFAULT_NOTEBOOKS_DIR}

WSL=false
_tmp=`uname -a | grep microsoft`
if [ ! -z "$_tmp" ]
then
  WSL=true
  echo "WARNING: WSL detected. Support for WSL is alpha only."
fi

. /etc/os-release
OS_FLAVOR=$ID
OS_RELEASE=$VERSION_ID
OS_RELEASE_MAJOR=${VERSION_ID%%.*} # extract major release, e.g. 1.2 -> 1, 1.2.3 -> 1

case $OS_FLAVOR$OS_RELEASE in
  ubuntu18.04 | ubuntu20.04 | rhel7* | rhel8* )
    ;;
  *)
    echo "Unknown system type: $OS_FLAVOR $OS_RELEASE"
    exit 1
    ;;
esac

PIN_CONTAINER="frolvlad/alpine-miniconda3:python3.7"
PIN_TMP="tmp.json"

REBOOT=0
LOGOUT=0

nvlog () {
  echo "###NV### `date` #### $1"
}

install_autocomplete() {
  if [ ! -f ~/.bash_completion ]
  then
    echo "#/usr/bin/env bash" > ~/.bash_completion
    cat dss.comp >> ~/.bash_completion
  else 
    # does the existing file contain the autocompletion already?
    _tmp=`grep "complete -F _dss ./data-science-stack" ~/.bash_completion`
    if [ -z "$_tmp" ]
    then
      # add our autocompletions
      cat dss.comp >> ~/.bash_completion
    fi
  fi
}

require_user () {
  if [ $(id -u) = 0 ]; then
    nvlog "ERROR: Cannot run this step as root, run script as user or without 'sudo'"
    exit 1
  fi
}

semver_gte () {
  # $1 >= $2 ?
  [ "$2" != "`echo -e "$1\n$2" | sort -V | head -n1`" ]
}


install_base () {
  nvlog "START Installing base packages"

  # Install base apt/yum packages needed
  set -e
  if [ $OS_FLAVOR = "ubuntu" ]; then
    sudo apt-get -y update --fix-missing
    sudo apt-get -y upgrade
    sudo apt-get -y install --no-install-recommends apt-utils
    sudo apt-get -y install \
      curl \
      font-manager \
      graphviz \
      git \
      gcc \
      g++ \
      jq \
      npm \
      screen \
      tzdata \
      wget \
      zlib1g-dev
  elif [ $OS_FLAVOR$OS_RELEASE_MAJOR = "rhel7" ]; then
    sudo subscription-manager repos --enable rhel-7-workstation-devtools-rpms
    sudo subscription-manager repos --enable rhel-7-workstation-optional-rpms
    sudo subscription-manager repos --enable rhel-7-workstation-extras-rpms
    sudo yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm || true
    sudo yum groups mark convert
    sudo yum groupinstall -y 'Development Tools'
    sudo yum install -y \
      bzip2 \
      clang \
      curl \
      device-mapper-persistent-data \
      devtoolset-4 \
      file \
      git \
      graphviz \
      jq \
      lvm2 \
      npm \
      screen \
      vim \
      wget \
      which \
      yum-utils
  else # RHEL 8
    sudo yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm || true
    sudo yum groupinstall -y 'Development Tools'
    sudo yum install -y \
      bzip2 \
      clang \
      curl \
      device-mapper-persistent-data \
      file \
      git \
      graphviz \
      jq \
      lvm2 \
      npm \
      screen \
      vim \
      wget \
      which \
      yum-utils
  fi
  set +e

  install_autocomplete
  
  nvlog "END Installing base packages"
}


detect_driver () {
  if [ -f /usr/bin/nvidia-smi ]; then
    DRIVER_VER=$(/usr/bin/nvidia-smi --query-gpu=driver_version --format=csv,noheader | head -n1 | cut -d " " -f1 2> /dev/null)
    if [ $? -ne 0 ]; then
      DRIVER_VER=0
    fi
    if [ $DRIVER_VER = "Failed" ]; then
      DRIVER_VER=0
    fi
  else
    DRIVER_VER=0
  fi
}


install_driver () {
  nvlog "START Installing Driver"

  if [ "$WSL" = true ]
  then
    nvlog "Driver installation is not needed in WSL - skip install"
    nvlog "END Installing Driver"
    return  
  fi

  if [ $OS_FLAVOR = "ubuntu" ]; then
    if [ -f /usr/bin/nvidia-uninstall ]; then
      cat << EOF

  Found /usr/bin/nvidia-uninstall which means a driver .run file was used
  on this machine. Driver install/update cannot proceed. The solution is to
  purge the driver and reinstall it with the correct apt repositories.

  Make sure you are connected to the internet and run:

    ${SCRIPT_NAME} purge-driver
    ${SCRIPT_NAME} install-driver

  Then rerun the command you just ran to proceed.

EOF
      exit 1
    fi
  fi

  semver_gte $DRIVER_VER $MIN_DRIVER
  if [ $? -eq 1 ]; then
    nvlog "Driver is new enough - skip install"
    nvlog "END Installing Driver"
    return
  fi

  set -e
  if [ $OS_FLAVOR = "ubuntu" ]; then
    sudo add-apt-repository -y ppa:graphics-drivers/ppa
    sudo apt-get -y update
    sudo apt-get -y upgrade
    sudo apt-get -y install nvidia-driver-455
    sudo apt-get -y autoremove
    REBOOT=1
  elif [ $OS_FLAVOR$OS_RELEASE_MAJOR = "rhel8" ]; then
    sudo dnf config-manager --add-repo http://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64/cuda-rhel8.repo
    sudo dnf install -y kernel-devel-$(uname -r) kernel-headers-$(uname -r)
    sudo dnf -y module install nvidia-driver:460-dkms
    # REBOOT not necessary
  else
    nvlog "Automated NVIDIA driver install on $OS_FLAVOR $OS_RELEASE is not supported."
    nvlog "Please install NVIDIA driver $MIN_DRIVER or newer and run again."
    exit 1
  fi
  set +e

  nvlog "END Installing Driver"
}


purge_driver () {
  nvlog "START Purge Driver"

  if [ "$WSL" = true ]
  then
    nvlog "Driver Purge is not needed in WSL - skip Purge"
    nvlog "END Purge Driver"
    return  
  fi  

  if [ $OS_FLAVOR != "ubuntu" ]; then
    nvlog "ERROR: Automated NVIDIA driver purge for Red Hat not supported."
    nvlog "Please run /usr/bin/nvidia-uninstall and reboot to remove driver."
    exit 1
  fi

  cat << EOF

WARNING:
Removing the NVIDIA Driver will also remove CUDA and other libraries like
nvidia-docker2 that depend on the driver.

Helpful once the system is rebooted:

    ${SCRIPT_NAME} setup-system

EOF

  read -p "DANGER: Are you SURE [y/N]?" -r
  if [[ $REPLY =~ ^[Yy]$ ]]; then
    nvlog "Starting removal..."
    if [ -f /usr/bin/nvidia-uninstall ]; then
      nvlog "Running /usr/bin/nvidia-uninstall first."
      sudo /usr/bin/nvidia-uninstall
    fi
    sudo apt-get -y purge nvidia-*
    sudo apt -y autoremove
    sudo rm -f /etc/modprobe.d/blacklist-nouveau.conf
    sudo rm -f /etc/modprobe.d/nvidia-installer-disable-nouveau.conf
    sudo update-initramfs -k all -u
    REBOOT=1
  else
    nvlog "Aborting - doing nothing"
  fi

  nvlog "END Purge Driver"
}


detect_cuda () {
  if [ -f /usr/local/cuda/version.txt ]; then
    CUDA_VER=$(cat /usr/local/cuda/version.txt | awk '{ print $3 }' 2> /dev/null)
    if [ $? -ne 0 ]; then
      CUDA_VER=0
    fi
  else
    CUDA_VER=0
  fi
}


install_cuda () {
  nvlog "START Installing CUDA"
  
  semver_gte $CUDA_VER $MIN_CUDA
  if [ $? -eq 1 ]; then
    nvlog "CUDA is new enough - skip install"
    nvlog "END Installing CUDA"
    return
  fi

  set -e
  if [ $OS_FLAVOR = "ubuntu" ]; then
    if [ $OS_RELEASE = "18.04" ]; then
      curl https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin \
        -o cuda.pin
      sudo mv cuda.pin /etc/apt/preferences.d/cuda-repository-pin-600
      sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub
      sudo add-apt-repository "deb http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/ /"
      sudo apt-get update
      sudo apt-get -y install cuda-toolkit-11-0
    else
      curl https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin \
        -o cuda.pin
      sudo mv cuda.pin /etc/apt/preferences.d/cuda-repository-pin-600
      sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/7fa2af80.pub
      sudo add-apt-repository "deb http://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /"
      sudo apt-get update
      sudo apt-get -y install cuda-toolkit-11-0
    fi
  else
    if [ $OS_FLAVOR$OS_RELEASE_MAJOR = "rhel7" ]; then
      sudo yum-config-manager --add-repo http://developer.download.nvidia.com/compute/cuda/repos/rhel7/x86_64/cuda-rhel7.repo
      sudo yum clean all
      sudo yum install -y cuda-toolkit-11-0
    else
      sudo dnf config-manager --add-repo http://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64/cuda-rhel8.repo
      sudo dnf clean all
      sudo dnf -y install cuda-toolkit-11-0
    fi
  fi
  set +e

  echo "export PATH=/usr/local/cuda/bin/:\$PATH # DATA-SCIENCE-STACK-ADDED" >> ${HOME}/.bashrc
  echo "export LD_LIBRARY_PATH=/usr/local/cuda-11.0/lib64:/lib:\$LD_LIBRARY_PATH # DATA-SCIENCE-STACK-ADDED" >> ${HOME}/.bashrc
  source ${HOME}/.bashrc

  nvlog "END Installing CUDA"
}


detect_docker () {
  DOCKER_VER=$(docker version --format '{{.Client.Version}}' 2> /dev/null)
  if [ $? -ne 0 ]; then
    DOCKER_VER=0
  fi
}


install_docker () {
  nvlog "START Installing Docker and NVIDIA Container Toolkit"
  semver_gte $DOCKER_VER $MIN_DOCKER
  if [ $? -eq 1 ]; then
    nvlog "Docker is new enough, checking for nvidia-docker2..."

    if [ $OS_FLAVOR = "ubuntu" ]; then
      nvd2=$(dpkg -l | grep nvidia-docker2 | grep ii)
    else
      nvd2=$(yum list installed | grep nvidia-docker2)
    fi

    if [ "$nvd2" != "" ]; then
      nvlog "nvidia-docker2 found, no install needed"
      nvlog "END Installing Docker and NVIDIA Container Toolkit"
      return
    fi
  fi

  set -e
  if [ $OS_FLAVOR = "ubuntu" ]; then
    # NVIDIA Repo
    curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
    curl -s -L https://nvidia.github.io/nvidia-docker/$OS_FLAVOR$OS_RELEASE/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
    # Docker Repo
    curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
    sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"

    sudo apt-get -y update
    sudo apt-get -y install \
      apt-transport-https \
      ca-certificates \
      gnupg-agent \
      software-properties-common
    sudo apt-get -y install \
      nvidia-docker2 \
      docker-ce \
      docker-ce-cli \
      containerd.io
    sudo systemctl enable docker
    sudo apt install -y acl

    nvlog "setting nvidia runtime as the default docker runtime"
    sudo mv /etc/docker/daemon.json /etc/docker/daemon.json.bak
    sudo cp docker/daemon.json /etc/docker/daemon.json

    if [ "$WSL" = true ] 
    then
      sudo /etc/init.d/docker start
      sudo groupadd -f docker
      sudo /etc/init.d/docker restart
      # wait for /var/run/docker.sock to be created
      while [ ! -S /var/run/docker.sock ]
      do
        nvlog "/var/run/docker.sock does not exist, waiting"
        sleep 1
      done
      nvlog "/var/run/docker.sock verified"
    else
      sudo systemctl start docker
      sudo groupadd -f docker
      sudo systemctl restart docker
    fi

  elif [ $OS_FLAVOR$OS_RELEASE_MAJOR = "rhel7" ]; then
    # NVIDIA Repos
    curl -s -L https://nvidia.github.io/nvidia-docker/$OS_FLAVOR$OS_RELEASE/nvidia-docker.repo | \
      sudo tee /etc/yum.repos.d/nvidia-docker.repo
    # Docker Repo
    sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo

    sudo yum install -y \
      nvidia-docker2 \
      docker-ce \
      docker-ce-cli \
      containerd.io
    sudo systemctl enable docker
    if [ "$WSL" = true ] 
    then
      sudo /etc/init.d/docker start
      sudo groupadd -f docker
      sudo /etc/init.d/docker restart
      # wait for /var/run/docker.sock to be created
      while [ ! -S /var/run/docker.sock ]
      do
        nvlog "/var/run/docker.sock does not exist, waiting"
        sleep 1
      done
      nvlog "/var/run/docker.sock verified"
    else
      sudo systemctl start docker
      sudo groupadd -f docker
      sudo systemctl restart docker
    fi

  else # RHEL 8
    # NVIDIA Repos
    curl -s -L https://nvidia.github.io/nvidia-docker/$OS_FLAVOR$OS_RELEASE/nvidia-docker.repo | \
      sudo tee /etc/yum.repos.d/nvidia-docker.repo
    # Docker Repo
    sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo

    # force new-enough containerd.io
    curl -s https://download.docker.com/linux/centos/7/x86_64/stable/Packages/containerd.io-1.2.13-3.2.el7.x86_64.rpm \
      --output containerd.rpm
    sudo yum localinstall -y containerd.rpm
    rm containerd.rpm

    sudo yum install -y \
      docker-ce \
      nvidia-container-toolkit
    sudo systemctl enable docker
    if [ "$WSL" = true ] 
    then
      sudo /etc/init.d/docker start
      sudo groupadd -f docker
      sudo /etc/init.d/docker restart
      # wait for /var/run/docker.sock to be created
      while [ ! -S /var/run/docker.sock ]
      do
        nvlog "/var/run/docker.sock does not exist, waiting"
        sleep 1
      done
      nvlog "/var/run/docker.sock verified"
    else
      sudo systemctl start docker
      sudo groupadd -f docker
      sudo systemctl restart docker
    fi

  fi

  set +e

  nvlog "END Installing Docker and NVIDIA Container Toolkit"
}


docker_adduser () {
  nvlog "START Add User to Docker Group"
  if groups $USER | grep -qw '\bdocker\b'; then
    nvlog "User already member of docker group"
    nvlog "END Add User to Docker Group"
    return
  fi

  set -e
  nvlog "Adding user '$USER' to docker group"
  sudo usermod -a -G docker $USER
  sudo setfacl -m user:$USER:rw /var/run/docker.sock
  if [ "$WSL" = true ] 
  then
    sudo /etc/init.d/docker restart
  else
    sudo systemctl daemon-reload
    sudo systemctl reload docker
  fi
  LOGOUT=1
  set +e

  nvlog "END Add User to Docker Group"
}


build_container () {
  nvlog "START Building Container - env:${ENVIRONMENT_NAME} => ${ENVIRONMENT_NAME}:${STACK_VERSION}"

  TEMPDIR=$(mktemp -d)

  nvlog "Run From: $RUNFROM"
  nvlog "Temp Directory: $TEMPDIR"
  cd $TEMPDIR
  cp -a $RUNFROM/data-science-stack.Dockerfile $RUNFROM/README.md $TEMPDIR
  cp -a $RUNFROM/environments/${ENVIRONMENT_NAME}-pinned.yaml $TEMPDIR/environment-pinned.yaml
  ls -aFl
  docker build \
    --tag ${ENVIRONMENT_NAME}:${STACK_VERSION} \
    -f ./data-science-stack.Dockerfile .
  rm -r $TEMPDIR

  nvlog "END Building Container"
  nvlog "Next you can run: ${SCRIPT_NAME} run-container"
}


purge_container () {
  nvlog "START Purge Container - env:${ENVIRONMENT_NAME} => ${ENVIRONMENT_NAME}:${STACK_VERSION}"


  read -p "DANGER: Are you sure you want to remove container ${ENVIRONMENT_NAME}:${STACK_VERSION} [y/N]?" -r
  if [[ $REPLY =~ ^[Yy]$ ]]; then
    nvlog "Removing container ${ENVIRONMENT_NAME}:${STACK_VERSION}"
    CMD="docker rmi -f ${ENVIRONMENT_NAME}:${STACK_VERSION}"
    nvlog "${CMD}"
    ${CMD}
  else
    nvlog "Aborting - no container deleted"
  fi

  nvlog "END Purge Container"
}


detect_conda () {
  CONDA_VER=$(conda --version 2> /dev/null)
  if [ $? -ne 0 ]; then
    CONDA_VER=0
    return
  fi
  CONDA_VER=$(echo "$CONDA_VER" | awk '{ print $2 }' 2> /dev/null)
  CONDA_ROOT=$(dirname $(dirname $(which conda)))
}


install_miniconda () {
  nvlog "START Install Miniconda"

  semver_gte $CONDA_VER $MIN_CONDA
  if [ $? -eq 1 ]; then
    nvlog "Conda is new enough"
    nvlog "END Install Miniconda"
    return
  elif [ $CONDA_VER != 0 ]; then
    nvlog
    nvlog "ERROR: Conda is installed but older, please update conda environment"
    nvlog "Try 'conda update -n base -c defaults conda'"
    nvlog
    exit 1
  fi

  if [ -d "${CONDA_ROOT}" ]; then
    nvlog
    nvlog "ERROR: Failed to detect Conda version but found a ${CONDA_ROOT} directory, please move/backup before install"
    nvlog
    exit 1
  fi

  set -e
  mkdir -p ${HOME}/.conda

  curl https://repo.anaconda.com/miniconda/Miniconda3-py37_$MIN_CONDA-Linux-x86_64.sh -o miniconda.sh
  chmod +x miniconda.sh
  ./miniconda.sh -bf -p ${CONDA_ROOT}  # Use the existing Conda
  rm -f ./miniconda.sh

  echo "export PATH=${CONDA_ROOT}/bin:\$PATH # DATA-SCIENCE-STACK-ADDED" >> ${HOME}/.bashrc
  source ${HOME}/.bashrc

  ${CONDA_ROOT}/bin/conda init bash
  source ${HOME}/.bashrc

  LOGOUT=1
  set +e

  nvlog "END Install Miniconda"
}


create_conda_env () {
  nvlog "START Setup Conda Env - env:${ENVIRONMENT_NAME} => ${ENVIRONMENT_NAME}-${STACK_VERSION}"

  if [ ! -f $RUNFROM/environments/${ENVIRONMENT_NAME}-pinned.yaml ]; then
      nvlog "ERROR: unknown environment '${ENVIRONMENT_NAME}', try $0 list"
      exit 1
  fi

  ${CONDA_ROOT}/bin/conda env create -n ${ENVIRONMENT_NAME}-${STACK_VERSION} \
    -f $RUNFROM/environments/${ENVIRONMENT_NAME}-pinned.yaml

  sed -i '/DATA-SCIENCE-STACK-ADDED-ACT/d' ${HOME}/.bashrc
  echo "conda activate ${ENVIRONMENT_NAME}-${STACK_VERSION} # DATA-SCIENCE-STACK-ADDED-ACT" >> ${HOME}/.bashrc
  if [ -d ${HOME}/Desktop/ ]; then
    cp $RUNFROM/README.md ${HOME}/Desktop/data-science-stack-README.md
  fi

  source ${CONDA_ROOT}/bin/activate ${ENVIRONMENT_NAME}-${STACK_VERSION} ; \
    jupyter labextension install -y --clean \
      @jupyter-widgets/jupyterlab-manager \
      jupyter-threejs \
      dask-labextension \
      jupyterlab-nvdashboard

  nvlog "END Setup Conda Env"
  nvlog "Next you can run: ${SCRIPT_NAME} run-jupyter"
}


purge_conda_env () {
  nvlog "START Purge Conda Env - env:${ENVIRONMENT_NAME} => ${ENVIRONMENT_NAME}-${STACK_VERSION}"

  read -p "DANGER: Are you sure you want to remove ${ENVIRONMENT_NAME}-${STACK_VERSION} [y/N]?" -r
  if [[ $REPLY =~ ^[Yy]$ ]]; then
    nvlog "Removing Conda environment ${ENVIRONMENT_NAME}-${STACK_VERSION}"

    sed -i '/DATA-SCIENCE-STACK-ADDED-ACT/d' ${HOME}/.bashrc
    nvlog "${CONDA_ROOT}/bin/conda env remove -n ${ENVIRONMENT_NAME}-${STACK_VERSION}"
    source ${CONDA_ROOT}/bin/deactivate ; \
      ${CONDA_ROOT}/bin/conda env remove -n ${ENVIRONMENT_NAME}-${STACK_VERSION}
    LOGOUT=1
  else
    nvlog "Aborting - no files deleted"
  fi

  nvlog "END Purge Conda Env"
}


install_notebooks () {
  nvlog "Start Install Notebooks"

  set -e
  nvlog "Installing Notebooks v${NOTEBOOKS_VERSION} to ${NOTEBOOKS_DIR}/"
  if [ ! -d "${NOTEBOOKS_DIR}" ]; then
    mkdir -p ${NOTEBOOKS_DIR}
  else
    if [ -d "${NOTEBOOKS_DIR}/notebooks" ]; then
      rm -rf ${NOTEBOOKS_DIR}/notebooks
    fi
  fi
  cd ${NOTEBOOKS_DIR}
  git clone --single-branch --depth 1 --branch branch-${NOTEBOOKS_VERSION} \
    https://github.com/rapidsai/notebooks.git
  cd notebooks
  git submodule update --init --remote
  rm -rf .git
  rm -rf `find repos/ -maxdepth 2 -mindepth 2 | grep -v notebooks`
  set +e

  nvlog "END Install Notebooks"
}


purge_conda () {
  nvlog "START Remove Conda"

  read -p "DANGER: Are you sure you want to remove ALL of Conda and ALL \
of NVIDIA Data Science Stack ( ${NOTEBOOKS_DIR} \
${HOME}/conda ${HOME}/.conda ) [y/N]?" -r
  if [[ $REPLY =~ ^[Yy]$ ]]; then
    nvlog "Removing Conda and Notebook files"
    if [ -f ${CONDA_ROOT}/bin/conda ]; then
      ${CONDA_ROOT}/bin/conda init --reverse
    fi
    rm -rf ${NOTEBOOKS_DIR}
    rm -rf ${HOME}/conda
    rm -rf ${HOME}/.conda
    nvlog "Saving ${HOME}/.bashrc to ${HOME}/.bashrc.bak"
    cp ${HOME}/.bashrc ${HOME}/.bashrc.bak
    sed -i '/DATA-SCIENCE-STACK-ADDED/d' ${HOME}/.bashrc
    LOGOUT=1
  else
    nvlog "Aborting - no files deleted"
  fi

  nvlog "END Remove Conda"
}


diagnostics () {
  nvlog "START Diagnostics"

  nvlog "Run as: $USER"
  nvlog "WSL: $WSL"
  nvlog "OS Flavor: $OS_FLAVOR"
  nvlog "OS Release: $OS_RELEASE"
  if [ -f /usr/bin/lsb_release ]; then
    nvlog "lsb_release:"
    /usr/bin/lsb_release -r -d
  fi
  if [ -f /bin/uname ]; then
    nvlog "uname -a"
    /bin/uname -a
  fi

  nvlog "Storage (non-tmpfs, non-loopback)"
  df -h | grep -v dev/loop | grep -v tmpfs

  nvlog "Network test"
  ping -c 1 -W 3 8.8.8.8

  nvlog "Driver detected (0 means not installed): $DRIVER_VER"

  if [ "$WSL" = false ]
  then
   nvlog "NVIDIA SMI:"
   if [ -f /usr/bin/nvidia-smi ]; then
    /usr/bin/nvidia-smi
   else
    echo "nvidia-smi not found, NVIDIA GPU Driver not installed correctly."
   fi
  fi

  nvlog "CUDA detected (0 means not installed): $CUDA_VER"
  nvlog "Docker detected (0 means not installed): $DOCKER_VER"

  nvlog "Shared libraries:"
  ldconfig -p | grep 'nvidia\|libnv\|cuda\|libcu'

  nvlog "Notebooks directory: $NOTEBOOKS_DIR"
  nvlog "Conda detected (0 means not installed): $CONDA_VER"
  nvlog "Target Conda root: $CONDA_ROOT"
  semver_gte $CONDA_VER $MIN_CONDA
  if [ $? -eq 1 ]; then
    nvlog "Conda packages:"
    conda list
  fi

  nvlog "END Diagnostics"
}


notify_reboot () {
  nvlog
  nvlog
  nvlog "ACTION REQUIRED:"
  nvlog "For the changes to take effect, reboot the machine."
  nvlog
  nvlog "Current working directory: `pwd`/"
  nvlog "data-science-stack script: ${RUNFROM}/${SCRIPT_NAME}"
  nvlog
  nvlog
}

get_latest_dss_version() {
  TEMPFILE=$(mktemp)
  curl --silent -o $TEMPFILE "https://api.github.com/repos/NVIDIA/data-science-stack/releases/latest"
  local GH_LATEST=$(cat $TEMPFILE | grep '"tag_name":' | sed -E 's/.*"([^"]+)".*/\1/')
  rm -f $TEMPFILE
  echo "$GH_LATEST"
}

upgrade() {
  lv=$(get_latest_dss_version)
  if [[ "$lv" == v* ]]; then
    lv=`echo $lv | cut -d 'v' -f2`
    cv=${STACK_VERSION}
    nvlog "local version: ${cv}, latest vesion: ${lv}"
    semver_gte $cv $lv
    if [ $? -eq 1 ]; then
      nvlog "already at the latest version"
      return
    fi
    nvlog "UPGRADE upgrading to version ${lv}"
    do_upgrade
  else
    nvlog "could not determine the latest data science stack version"
    return
  fi
}

do_upgrade() {
  nvlog "UPGRADE starting"
  ENVIRONMENT_NAME=${DEFAULT_ENVIRONMENT}
  # remove the default docker container image if it exists
  if [ $DOCKER_VER != 0 ]; then
    purge_container
  fi
  # remove the default conda env if it exists
  if [ $CONDA_VER != 0 ]; then
    purge_conda_env
  fi
  # We don't completely wipe the system here, we just install the new script[s]
  # While this may lack rigor, it also should save time

  # back up the current (old) version of the stack
  mv ${HOME}/data-science-stack ${HOME}/data-science-stack-backup-${STACK_VERSION}
  cd ${HOME}
  # install the new version
  git clone https://github.com/NVIDIA/data-science-stack.git
  cd ${HOME}/data-science-stack
  bash ./data-science-stack setup-system
  cd ${HOME}
  nvlog "UPGRADE done, please log out and log in"
}

notify_logout () {
  nvlog
  nvlog
  nvlog "ACTION REQUIRED:"
  nvlog "For the changes to take effect, please logout and login back in."
  nvlog
  nvlog "Current working directory: `pwd`/"
  nvlog "data-science-stack script: ${RUNFROM}/${SCRIPT_NAME}"
  nvlog
  nvlog
}


NOTEBOOK_OVERRIDE_CODE="
def my_run_line_magic(*args, **kwargs):
  g=globals()
  l={}
  for a in args:
    try:
      exec(str(a),g,l)
    except Exception as e:
      print('WARNING: %s\n   While executing this magic function code:\n%s\n   continuing...\n' % (e, a))
    else:
      g.update(l)

def my_run_cell_magic(*args, **kwargs):
  my_run_line_magic(*args, **kwargs)

get_ipython().run_line_magic=my_run_line_magic
get_ipython().run_cell_magic=my_run_cell_magic
"


run_notebook () {
  nvlog "START running $1"

  NBFILENAME=$(basename $1)
  NBNAME=${NBFILENAME%.*}
  NBNAME=${NBNAME##*/}
  NBTESTSCRIPT=/tmp/${NBNAME}-test.py
  TEMPFILE=$(mktemp)

  pushd $(dirname $1)

  jupyter nbconvert --to script ${NBFILENAME} --output /tmp/${NBNAME}-test
  echo "${NOTEBOOK_OVERRIDE_CODE}" > ${TEMPFILE}
  cat ${NBTESTSCRIPT} >> ${TEMPFILE}
  mv ${TEMPFILE} ${NBTESTSCRIPT}

  nvlog "Running \"ipython --colors=NoColor ${NBTESTSCRIPT}\" on $(date)"
  time ipython --colors=NoColor ${NBTESTSCRIPT}
  NBEXITCODE=$?
  nvlog "EXIT CODE: ${NBEXITCODE}"
  rm -f $TEMPFILE
  rm -f $NBTESTSCRIPT

  popd

  nvlog "END running $1"
}


install_kubernetes() {
  nvlog "START Kubernetes install with kubeadm"

  if [ $OS_FLAVOR != "ubuntu" ]; then
    nvlog "ERROR: Automated Kubernetes install for Red Hat not supported."
    exit 1
  fi 

  set -e
  sudo apt-get update && sudo apt-get install -y apt-transport-https curl
  curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
  echo "deb https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
  sudo apt-get update
  sudo apt-get install -y kubelet kubeadm kubectl
  sudo apt-mark hold kubelet kubeadm kubectl

  # Init cluster w/Flannel
  nvlog "NOTE: disabling swap (paging to disk)"
  sudo swapoff -a
  sudo kubeadm init --pod-network-cidr 10.244.0.0/16

  # Setup credentials for user
  mkdir -p $HOME/.kube
  sudo cp /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown -R $(id -u):$(id -g) $HOME/.kube/

  # Allow scheduling on master node since there is only one node
  kubectl taint nodes --all node-role.kubernetes.io/master-

  # Flannel
  sudo sysctl net.bridge.bridge-nf-call-iptables=1
  kubectl apply -f \
    https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml

  # NVIDIA Device Plugin
  kubectl create -f \
    https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/master/nvidia-device-plugin.yml


  # Smoke test
  sleep 5
  nvlog
  nvlog
  nvlog "Kubernetes cluster will take some time to pull images and start"
  nvlog "but here is what's running so far (from 'kubectl get all --all-namespaces')"
  nvlog
  nvlog
  kubectl get all --all-namespaces

  set +e

  nvlog "END Kubernetes install with kubeadm"
}

install_jupyter-repo2docker() {
  nvlog "START jupyter-repo2docker install"
  
  if [ $OS_FLAVOR = "ubuntu" ]; then
    sudo apt install -y python3-pip
    pip3 install jupyter-repo2docker
  else #RHEL
    sudo yum install -y python3-pip
    pip3 install jupyter-repo2docker
  fi 
  nvlog "END jupyter-repo2docker install"
}

purge_jupyter-repo2docker() {
  nvlog "START jupyter-repo2docker purge"
  
  # let us not remove python-pip as it may be used for other things in the future
  if [ $OS_FLAVOR = "ubuntu" ]; then
    pip3 uninstall -y jupyter-repo2docker
  else #RHEL
    pip3 uninstall -y jupyter-repo2docker
  fi 
  nvlog "END jupyter-repo2docker purge"
}


purge_kubernetes() {
  nvlog "START Kubernetes purge with kubeadm"

  if [ $OS_FLAVOR != "ubuntu" ]; then
    nvlog "ERROR: Automated Kubernetes purge for Red Hat not supported."
    exit 1
  fi

 cat << EOF

WARNING:
  Removing Kubernetes this way should ONLY be done if it was setup
  with this script and the install-kubernetes command.

  This will destroy the Kubernetes cluster which cannot be undone.

EOF

  set -e
  read -p "DANGER: Are you SURE [y/N]?" -r
  if [[ $REPLY =~ ^[Yy]$ ]]; then
    nvlog "Starting removal..."
    sudo kubeadm reset
    sudo ip link set dev flannel.1 down
    sudo ip link delete flannel.1
    sudo rm -f /etc/apt/sources.list.d/kubernetes.list
    sudo rm -rf /etc/kubernetes/
    rm -rf $HOME/.kube/

    read -p "Reenable swap (paging to disk)? [Y/n]?" -r
    if [[ $REPLY =~ ^[Yy]$ ]]; then
      sudo swapon -a
    fi
  else
    nvlog "Aborting - doing nothing"
  fi
  set +e

  nvlog "END Kubernetes purge with kubeadm"
}



usage () {
  more << EOF

NVIDIA Data Science Stack v${STACK_VERSION}

Usage: ${SCRIPT_NAME} COMMAND

Information Commands:
    help
        Display help and usage.
    version
        Display version information. Version:, Latest:,
        and an Error: if the current release version cannot be retrieved.
    list
        List the available environments.
    diagnostics
        Display stack software versions and info.

Setup Commands:

    setup-system
        Setup system to enable NVIDIA Data Science software.
    upgrade
        Upgrades to the latest version, if the latest version is available

Containers Commands:

    build-container <environment-name>
        Build the container version of the stack.
        Default <environment-name> is "${DEFAULT_ENVIRONMENT}".
    run-container <environment-name>
        Run Jupyter in the container.
        Default <environment-name> is "${DEFAULT_ENVIRONMENT}".

Conda Local Environments Commands:

    build-conda-env <environment-name>
        Build the Conda environment version of the stack.
        Default <environment-name> is "${DEFAULT_ENVIRONMENT}".
    run-jupyter <environment-name>
        Run Jupyter in the environment.
        Default <environment-name> is "${DEFAULT_ENVIRONMENT}".

Environment Pinning Commands (for stack maintainers):

    pin <environment-name>
        Generates a <environment-name>-pinned.yaml file based on the
        "./environments/<environment-name>.env" file.
        Default <environment-name> is "${DEFAULT_ENVIRONMENT}".
        See environments/README.md for more information and debugging.
    pin-clean
        Cleans up temporary files and containers from pinning process.

Notebook Commands:

    run-notebook <notebook-name.ipynb>
        Run a notebook in the terminal, time it, and display exit code.
    run-notebook-dir <notebook-directory>
        Runs all the notebooks in a directory tree like the run-notebook
        command does.

Other Subcommands:

  WARNING:
  These subcommands run parts of the above commands, and should be used with
  caution as the ordering and dependencies ARE NOT currently enforced by
  the subcommands.

    install-base
        Install base dependencies needed by stacks with apt/yum.
    install-driver
        Install the NVIDIA GPU driver v${MIN_DRIVER}+.
        Automated install not supported on Red Hat.
    purge-driver
        Purge the NVIDIA GPU driver from the system, before a clean reinstall.
        Automated purge not supported on Red Hat.
    install-docker
        Install Docker CE v${MIN_DOCKER}+.
    setup-user
        Setup user permissions to use docker. Useful when multiple users
        use a machine. Normal done by setup-system for first user.
        The user must have sudo permission.
    install-cuda
        Install the NVIDIA CUDA Toolkit v${MIN_CUDA}+
    install-miniconda
        Install Miniconda v${MIN_CONDA}+.
    purge-container <environment-name>
        Removes the container.
    create-conda-env <environment-name>
        Creates a new conda environment from pinned environment.
    purge-conda-env <environment-name>
        Removes the conda environment.
    purge-conda
        DANGER: Purge the account of Conda and the software stack.
    install-notebooks
        Download the RAPIDS example notebooks to:
          ${NOTEBOOKS_DIR}
    install-kubernetes
        Install a local Kubernetes stack with kubeadm
    purge-kubernetes
        DANGER: Purge the local Kubernetes stack installed with this
        script's install-kubernetes command.
    install-tools
        Install the local tools (currently, only jupyter-repo2docker, but this list may grow over time)
    purge-tools
        DANGER: Purge local tools (currently, only jupyter-repo2docker)
        script's install-kubernetes command.

EOF
}

(
detect_driver
detect_cuda
detect_docker
detect_conda

case "$1" in
  version)
    echo Version: ${STACK_VERSION}
    GH_LATEST=$(get_latest_dss_version)
    if [[ $GH_LATEST == v* ]]; then
      echo Latest: $GH_LATEST
    else
      echo Latest: unknown
      echo Error: `cat $TEMPFILE`
    fi

    ;;

  list)
    echo "Environments available: (default is ${DEFAULT_ENVIRONMENT})"
    cd environments && ls *.env | sed s/.env//g
    ;;

  diagnostics)
    require_user
    diagnostics
    ;;

  setup-system)
    require_user
    nvlog "OS Flavor: $OS_FLAVOR"
    nvlog "Driver detected: $DRIVER_VER"
    nvlog "Docker detected: $DOCKER_VER"
    install_base
    install_driver
    install_docker
    docker_adduser
    ;;

  upgrade)
    upgrade
    ;;

  build-container)
    ENVIRONMENT_NAME="${2:-$DEFAULT_ENVIRONMENT}"
    build_container
    ;;
  purge-container)
    ENVIRONMENT_NAME="${2:-$DEFAULT_ENVIRONMENT}"
    purge_container
    ;;

  build-conda-env)
    ENVIRONMENT_NAME="${2:-$DEFAULT_ENVIRONMENT}"
    require_user
    install_cuda
    install_miniconda
    create_conda_env
    install_notebooks
    LOGOUT=1
    ;;

  run-container)
    ENVIRONMENT_NAME="${2:-$DEFAULT_ENVIRONMENT}"
    nvlog "Running NVIDIA Data Science container, accessible at http://localhost:8888/"
    nvlog "Be sure your machine is not exposed to the internet."
    nvlog "Command: docker run --gpus all --rm -it -p 8888:8888 -p 8787:8787 -p 8786:8786 ${ENVIRONMENT_NAME}:${STACK_VERSION}"
    docker run --gpus all --rm -it -p 8888:8888 -p 8787:8787 -p 8786:8786 ${ENVIRONMENT_NAME}:${STACK_VERSION}
    ;;

  run-jupyter)
    ENVIRONMENT_NAME="${2:-$DEFAULT_ENVIRONMENT}"
    if [ "$WSL" = false ]
    then
      SYSTEM_GPUS="$(/usr/bin/nvidia-smi -L | wc -l)"
      export MAXGPUS=${MAXGPUS:-$SYSTEM_GPUS}
      nvlog "Max GPUs = $MAXGPUS"
    fi
    source ${CONDA_ROOT}/bin/activate ${ENVIRONMENT_NAME}-${STACK_VERSION}
    nvlog "Command: jupyter-lab --no-browser --ip=0.0.0.0 --notebook-dir=${NOTEBOOKS_DIR}"
    jupyter-lab --no-browser --ip=0.0.0.0 --notebook-dir=${NOTEBOOKS_DIR}
    ;;

  install-base)
    install_base
    ;;
  install-driver)
    install_driver
    ;;
  purge-driver)
    purge_driver
    ;;
  install-docker)
    install_docker
    ;;
  setup-user)
    require_user
    docker_adduser
    ;;

  install-cuda)
    install_cuda
    ;;
  install-miniconda)
    require_user
    install_miniconda
    ;;
  create-conda-env)
    ENVIRONMENT_NAME="${2:-$DEFAULT_ENVIRONMENT}"
    require_user
    nvlog "Conda detected: $CONDA_VER"
    nvlog "Conda root: $CONDA_ROOT"
    create_conda_env
    ;;
  purge-conda-env)
    ENVIRONMENT_NAME="${2:-$DEFAULT_ENVIRONMENT}"
    require_user
    purge_conda_env
    ;;
  install-notebooks)
    require_user
    install_notebooks
    ;;

  purge-conda)
    require_user
    purge_conda
    ;;

  pin)
    ENVIRONMENT_NAME="${2:-$DEFAULT_ENVIRONMENT}"
    PIN_OUT=${ENVIRONMENT_NAME}-pinned.yaml
    nvlog "START Pinning versions to ${PIN_OUT}"
    docker pull ${PIN_CONTAINER}
    ENVFILE=${RUNFROM}/environments/${ENVIRONMENT_NAME}.env
    if [ ! -f ${ENVFILE} ]; then
      nvlog "${ENVFILE} not found. Exiting."
      exit 1
    fi
    ENV_COMMAND=$(cat "${ENVFILE}")
    CMD=$(echo "docker run --rm ${PIN_CONTAINER} \
      conda create --name snapper --override-channels \
      ${ENV_COMMAND} --dry-run" | tr "\n" " " | tr -s [:space:] " ")
    nvlog "${CMD}"
    nvlog "This will take a while..."
    if ${CMD} --json > ${PIN_TMP}
    then
      echo -e "# GENERATED FILE DO NOT EDIT\nchannels:" > ${PIN_OUT}
      grep "^-c" ${ENVFILE} | sed "s/-c /  - /g" >> ${PIN_OUT}
      echo "dependencies:" >> ${PIN_OUT}
      jq -r '[.actions.LINK[]] | sort_by(.name) | .[] | "  - \(.channel)::\(.name)=\(.version)"' ${PIN_TMP} >> ${PIN_OUT}
    else
      cat ${PIN_TMP}
    fi
    rm ${PIN_TMP}
    nvlog "END Pinning versions to ${PIN_OUT}"
    ;;

  pin-clean)
    nvlog "START Removing pin container"
    rm ${PIN_TMP}
    docker rmi -f ${PIN_CONTAINER}
    nvlog "END Removing pin container"
    ;;

  run-notebook)
    if [ $# -ne 2 ]; then
      nvlog "Usage: ${SCRIPT_NAME} run-notebook <notebook-file>"
    fi;
    run_notebook $2
    ;;

  run-notebook-dir)
    if [ $# -ne 2 ]; then
      nvlog "Usage: ${SCRIPT_NAME} run-notebook-dir <notebook-directory>"
    fi;
    cd $2
    for nb in $(find . -name "*.ipynb"); do
      # Skip all NBs that use dask (in the code or even in their name)
      if ((echo ${nb}|grep -qi dask) || (grep -q dask ${nb})); then
        nvlog "SKIPPING: ${nb} (suspected Dask usage, not currently automatable)"
      else
        run_notebook ${nb}
      fi
    done
    ;;

  install-kubernetes)
    require_user
    install_kubernetes
    ;;
  purge-kubernetes)
    require_user
    purge_kubernetes
    ;;

  install-tools)
    require_user
    install_jupyter-repo2docker
    nvlog "please logout and login again"
    ;;
  purge-tools)
    require_user
    purge_jupyter-repo2docker
    ;;

  help)
    usage
    ;;

  *)
    usage
    ;;
esac

if [ $REBOOT -ne 0 ]; then
  notify_reboot
  exit 0
fi

if [ $LOGOUT -ne 0 ]; then
  notify_logout
  exit 0
fi

)2>&1 | tee -a $LOGFILE
